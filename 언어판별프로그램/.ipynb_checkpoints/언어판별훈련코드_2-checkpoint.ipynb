{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "# 알파벳 출현 빈도 데이터 읽어 들이기 --- (※1)\n",
    "with open(\"./lang/freq.json\", \"r\", encoding=\"utf-8\") as fp:\n",
    "    freq = json.load(fp)\n",
    "# 언어마다 계산하기 --- (※2)\n",
    "lang_dic = {}\n",
    "for i, lbl in enumerate(freq[0][\"labels\"]):\n",
    "    fq = freq[0][\"freqs\"][i]\n",
    "    if not (lbl in lang_dic):\n",
    "        lang_dic[lbl] = fq\n",
    "        continue\n",
    "    for idx, v in enumerate(fq):\n",
    "        lang_dic[lbl][idx] = (lang_dic[lbl][idx] + v) / 2\n",
    "# Pandas의 DataFrame에 데이터 넣기 --- (※3)\n",
    "asclist = [[chr(n) for n in range(97,97+26)]]\n",
    "df = pd.DataFrame(lang_dic, index=asclist)\n",
    "# 그래프 그리기 --- (※4)\n",
    "plt.style.use('ggplot')\n",
    "df.plot(kind=\"bar\", subplots=True, ylim=(0,0.15))\n",
    "plt.savefig(\"lang-plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm \n",
    "from sklearn.externals import joblib\n",
    "import json\n",
    "# 각 언어의 출현 빈도 데이터(JSON) 읽어 들이기\n",
    "with open(\"./lang/freq.json\", \"r\", encoding=\"utf-8\") as fp:\n",
    "    d = json.load(fp)\n",
    "    data = d[0]\n",
    "# 데이터 학습하기\n",
    "clf = svm.SVC()\n",
    "clf.fit(data[\"freqs\"], data[\"labels\"])\n",
    "# 학습 데이터 저장하기\n",
    "joblib.dump(clf, \"./lang/freq.pkl\")\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 = 0.875\n",
      "리포트 =\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          en       0.67      1.00      0.80         2\n",
      "          fr       1.00      1.00      1.00         2\n",
      "          id       1.00      0.50      0.67         2\n",
      "          tl       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.92      0.88      0.87         8\n",
      "weighted avg       0.92      0.88      0.87         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "import glob, os.path, re, json\n",
    "# 텍스트를 읽어 들이고 출현 빈도 조사하기 --- (※1)\n",
    "\n",
    "## function (먼저 쓰이는 순서대로)\n",
    "\n",
    "def check_freq(fname):\n",
    "    name = os.path.basename(fname)\n",
    "    lang = re.match(r'^[a-z]{2,}', name).group()\n",
    "    with open(fname, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    text = text.lower() # 소문자 변환\n",
    "    # 숫자 세기 변수(cnt) 초기화하기\n",
    "    cnt = [0 for n in range(0, 26)]\n",
    "    code_a = ord(\"a\")\n",
    "    code_z = ord(\"z\")\n",
    "    # 알파벳 출현 횟수 구하기 --- (※2)\n",
    "    for ch in text:\n",
    "        n = ord(ch)\n",
    "        if code_a <= n <= code_z: # a~z 사이에 있을 때\n",
    "            cnt[n - code_a] += 1\n",
    "    # 정규화하기 --- (※3)\n",
    "    total = sum(cnt)\n",
    "    freq = list(map(lambda n: n / total, cnt))\n",
    "    return (freq, lang)\n",
    "    \n",
    "# 각 파일 처리하기\n",
    "def load_files(path):\n",
    "    freqs = []\n",
    "    labels = []\n",
    "    file_list = glob.glob(path)\n",
    "    for fname in file_list:\n",
    "        r = check_freq(fname)\n",
    "        freqs.append(r[0])\n",
    "        labels.append(r[1])\n",
    "    return {\"freqs\":freqs, \"labels\":labels}\n",
    "\n",
    "\n",
    "\n",
    "## 메인코드\n",
    "\n",
    "\n",
    "data = load_files(\"./lang/train/*.txt\")\n",
    "test = load_files(\"./lang/test/*.txt\")\n",
    "# 이후를 대비해서 JSON으로 결과 저장하기\n",
    "with open(\"./lang/freq.json\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    json.dump([data, test], fp)\n",
    "# 학습하기 --- (※4)\n",
    "clf = svm.SVC()\n",
    "clf.fit(data[\"freqs\"], data[\"labels\"])\n",
    "# 예측하기 --- (※5)\n",
    "predict = clf.predict(test[\"freqs\"])\n",
    "# 결과 테스트하기 --- (※6)\n",
    "ac_score = metrics.accuracy_score(test[\"labels\"], predict)\n",
    "cl_report = metrics.classification_report(test[\"labels\"], predict)\n",
    "print(\"정답률 =\", ac_score)\n",
    "print(\"리포트 =\")\n",
    "print(cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 = 0.875\n",
      "리포트 =\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          en       0.67      1.00      0.80         2\n",
      "          fr       1.00      1.00      1.00         2\n",
      "          id       1.00      0.50      0.67         2\n",
      "          tl       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.92      0.88      0.87         8\n",
      "weighted avg       0.92      0.88      0.87         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "import glob, os.path, re, json\n",
    "# 텍스트를 읽어 들이고 출현 빈도 조사하기 --- (※1)\n",
    "\n",
    "## function (먼저 쓰이는 순서대로)\n",
    "\n",
    "def check_freq(fname):\n",
    "    name = os.path.basename(fname)\n",
    "    lang = re.match(r'^[a-z]{2,}', name).group()\n",
    "    with open(fname, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    text = text.lower() # 소문자 변환\n",
    "    # 숫자 세기 변수(cnt) 초기화하기\n",
    "    cnt = [0 for n in range(0, 26)]\n",
    "    code_a = ord(\"a\")\n",
    "    code_z = ord(\"z\")\n",
    "    # 알파벳 출현 횟수 구하기 --- (※2)\n",
    "    for ch in text:\n",
    "        n = ord(ch)\n",
    "        if code_a <= n <= code_z: # a~z 사이에 있을 때\n",
    "            cnt[n - code_a] += 1\n",
    "    # 정규화하기 --- (※3)\n",
    "    total = sum(cnt)\n",
    "    freq = list(map(lambda n: n / total, cnt))\n",
    "    return (freq, lang)\n",
    "    \n",
    "# 각 파일 처리하기\n",
    "def load_files(path):\n",
    "    freqs = []\n",
    "    labels = []\n",
    "    file_list = glob.glob(path)\n",
    "    for fname in file_list:\n",
    "        r = check_freq(fname)\n",
    "        freqs.append(r[0])\n",
    "        labels.append(r[1])\n",
    "    return {\"freqs\":freqs, \"labels\":labels}\n",
    "\n",
    "\n",
    "\n",
    "## 메인코드\n",
    "\n",
    "\n",
    "data = load_files(\"./lang/train/*.txt\")\n",
    "test = load_files(\"./lang/test/*.txt\")\n",
    "# 이후를 대비해서 JSON으로 결과 저장하기\n",
    "with open(\"./lang/freq.json\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    json.dump([data, test], fp)\n",
    "# 학습하기 --- (※4)\n",
    "clf = svm.SVC()\n",
    "clf.fit(data[\"freqs\"], data[\"labels\"])\n",
    "# 예측하기 --- (※5)\n",
    "predict = clf.predict(test[\"freqs\"])\n",
    "# 결과 테스트하기 --- (※6)\n",
    "ac_score = metrics.accuracy_score(test[\"labels\"], predict)\n",
    "cl_report = metrics.classification_report(test[\"labels\"], predict)\n",
    "print(\"정답률 =\", ac_score)\n",
    "print(\"리포트 =\")\n",
    "print(cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
